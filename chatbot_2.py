# -*- coding: utf-8 -*-
"""Untitled58.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cjs-WRgqbbM1ZsngQW8BfhfrZ8EE6GA0
"""

import json
import numpy as np
from transformers import pipeline
import matplotlib.pyplot as plt
import logging
from IPython.display import display

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

distilbert_classifier = pipeline("text-classification", model="distilbert-base-uncased-finetuned-sst-2-english")

faq_data = '''
{
    "general":{
        "Hi":"Hello",
        "Good morning":"Good morning",
        "Good afternoon":"Good afternoon"
  },
    "specifications": {
        "What are the specs of the latest smartphone?": "Our latest smartphone features a 6.7-inch OLED display, 128GB storage, 8GB RAM, 48MP camera, and 5G support.",
        "What are the laptop specifications?": "Our latest laptop has a 16-inch Retina display, 16GB RAM, 512GB SSD, Intel i7 processor, and 12-hour battery life.",
        "What is the camera resolution of the new phone?": "The new smartphone has a 48MP main camera and a 12MP front camera."
    },
    "orders": {
        "How can I track my order?": "You can track your order using the tracking link sent to your email or by logging into your account on our website.",
        "Where is my order?": "Please provide your order number, and I can check the status for you.",
        "How long does shipping take?": "Standard shipping takes 3-5 business days; expedited shipping takes 1-2 days."
    },
    "returns": {
        "What is the return policy?": "We offer a 30-day return policy for unused items in original packaging. Contact support to initiate a return.",
        "Can I return an opened product?": "Opened products may be returned within 30 days if defective, but a restocking fee may apply."
    },
    "payment": {
        "What payment methods are available?": "We accept credit/debit cards, PayPal, bank transfers, and Apple Pay.",
        "Do you offer installment payments?": "Yes, we offer installment plans via Klarna and Afterpay for eligible purchases."
    },
    "warranty": {
        "What is the warranty on products?": "All products come with a 1-year limited warranty covering manufacturing defects.",
        "How do I claim warranty?": "Contact support with your order number and issue details to start a warranty claim."
    },
    "promotions": {
        "Are there any discounts available?": "Current promotions include 10% off smartphones with code SAVE10 and free shipping on orders over $100.",
        "How do I apply a promo code?": "Enter the promo code at checkout on our website to apply the discount."
    },
    "support": {
        "How do I contact customer support?": "Reach us at support@gadgets.com or call 1-800-555-1234, Mon-Fri, 9 AM-5 PM.",
        "What are your support hours?": "Our support team is available Monday to Friday, 9 AM to 5 PM EST."
    }
}
'''

def load_faqs():
    return json.loads(faq_data)

class CustomerSupportBot:
    def __init__(self, model_name, classifier=None, generative_model=None, tokenizer=None):
        self.faqs = load_faqs()
        self.conversation_history = []
        self.max_history = 3
        self.model_name = model_name
        self.classifier = classifier
        self.generative_model = generative_model
        self.tokenizer = tokenizer
        self.confidence_threshold = 0.7

    def classify_intent(self, query):
        """Classify the user query to a FAQ category."""
        if not self.classifier:
            return None, None, 0
        scores = {}
        for category, qa_pairs in self.faqs.items():
            for question in qa_pairs.keys():
                input_text = f"Query: {query} FAQ: {question}"
                result = self.classifier(input_text)
                score = result[0]['score'] if result[0]['label'] == 'POSITIVE' else 1 - result[0]['score']
                scores[(category, question)] = score
        if not scores:
            return None, None, 0
        best_match = max(scores, key=scores.get)
        return best_match[0], best_match[1], scores[best_match]

    def get_generative_response(self, user_input, context):
        """Generate a response using distilgpt2."""
        prompt = f"""
        You are a customer support chatbot for an electronics company. Use the following FAQ data to answer queries:
        {json.dumps(self.faqs, indent=2)}

        Conversation history:
        {context}

        User query: {user_input}

        Provide an accurate, concise response. If the query matches an FAQ, use the exact answer. If unclear or not in FAQs, provide a helpful response or ask for clarification. Escalate to support@gadgets.com if needed.
        """
        inputs = self.tokenizer(prompt, return_tensors="pt", max_length=512, truncation=True)
        outputs = self.generative_model.generate(**inputs, max_new_tokens=150, temperature=0.7)
        response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)
        return response.strip().split("User query:")[1].strip() if "User query:" in response else response.strip()

    def get_response(self, user_input):
        """Generate a response based on user input and conversation context."""
        logger.info(f"Processing user input for {self.model_name}: {user_input}")
        self.conversation_history.append({"role": "user", "content": user_input})
        context = " ".join([f"{turn['role']}: {turn['content']}" for turn in self.conversation_history[-self.max_history:]])

        if self.classifier:
            category, question, confidence = self.classify_intent(user_input)
            if confidence > self.confidence_threshold:
                response = self.faqs[category][question]
            else:
                response = self.get_generative_response(user_input, context) if self.model_name == "distilgpt2" else \
                           "I'm sorry, I didn't understand your question. Could you clarify or ask something else? Contact support@gadgets.com if needed."
        else:
            response = self.get_generative_response(user_input, context)

        self.conversation_history.append({"role": "bot", "content": response})
        logger.info(f"{self.model_name} response: {response}")
        return response

    def reset_history(self):
        """Reset conversation history."""
        self.conversation_history = []

def run_chatbot():
    bot = CustomerSupportBot()
    print("Welcome to the Customer Support Chatbot! Type 'exit' to quit.")

    while True:
        user_input = input("You: ")
        if user_input.lower() == 'exit':
            print("Goodbye!")
            break
        response = bot.get_response(user_input)
        print(f"Bot: {response}")

plot_conversation_flow()

distilbert_bot = CustomerSupportBot(model_name="DistilBERT", classifier=distilbert_classifier)

print("=== DistilBERT Chatbot ===")
print("Welcome to the DistilBERT Customer Support Chatbot! Type 'exit' to quit.")

while True:
    user_input = input("You: ")
    if user_input.lower() == 'exit':
        print("Goodbye from DistilBERT!")
        break
    response = distilbert_bot.get_response(user_input)
    print(f"DistilBERT Bot: {response}")

roberta_bot = CustomerSupportBot(model_name="RoBERTa", classifier=roberta_classifier)

print("=== RoBERTa Chatbot ===")
print("Welcome to the RoBERTa Customer Support Chatbot! Type 'exit' to quit.")

while True:
    user_input = input("You: ")
    if user_input.lower() == 'exit':
        print("Goodbye from RoBERTa!")
        break
    response = roberta_bot.get_response(user_input)
    print(f"RoBERTa Bot: {response}")

from transformers import AutoTokenizer, AutoModelForCausalLM

model_name = "distilgpt2"
tokenizer = AutoTokenizer.from_pretrained(model_name)
grok_model = AutoModelForCausalLM.from_pretrained(model_name)

grok_bot = CustomerSupportBot(model_name="distilgpt2", generative_model=grok_model, tokenizer=tokenizer)

print("=== distilgpt2 Chatbot ===")
print("Welcome to the distilgpt2 Customer Support Chatbot! Type 'exit' to quit.")

while True:
    user_input = input("You: ")
    if user_input.lower() == 'exit':
        print("Goodbye from distilgpt2!")
        break
    response = grok_bot.get_response(user_input)
    print(f"distilgpt2 Bot: {response}")

